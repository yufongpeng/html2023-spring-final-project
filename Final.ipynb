{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DqDuEVzvTDTu",
        "lqgWUGvTTOAV",
        "vFoPts6b376S"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Package Import"
      ],
      "metadata": {
        "id": "DqDuEVzvTDTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bc7PKFk0zIna"
      },
      "outputs": [],
      "source": [
        "### import\n",
        "import random as rand\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier, RandomForestRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, ConfusionMatrixDisplay\n",
        "\n",
        "from scipy.stats import iqr\n",
        "\n",
        "from statsmodels.miscmodels.ordinal_model import OrderedModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data & Preprocess Func\n",
        "panda: y_train_pd, x_train_pd\n",
        "\n",
        "numpy: y_train, x_train (w/ missing value), x_train_std (imputed according to current method)"
      ],
      "metadata": {
        "id": "lqgWUGvTTOAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### missing value\n",
        "# x should be pandas dataframe\n",
        "def KNN_Impute(x, k):\n",
        "    knn_impute = KNNImputer(n_neighbors=k) # n_neighbors, weights\n",
        "    x = knn_impute.fit_transform(x)\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][1] = round(x[i][1])\n",
        "    return x\n",
        "\n",
        "def KNN_Impute_iqrs(x, k):\n",
        "    iqrs = x.apply(lambda x: np.nanquantile(x, 0.75) - np.nanquantile(x, 0.25))\n",
        "    x = x / iqrs\n",
        "    knn_impute = KNNImputer(n_neighbors=k) # n_neighbors, weights\n",
        "    x = knn_impute.fit_transform(x)\n",
        "    x = x * iqrs.to_numpy()\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][1] = round(x[i][1])\n",
        "    return x"
      ],
      "metadata": {
        "id": "lhgxBmg2_wLn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### load training data with pandas\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\", delimiter=\",\", header=0)\n",
        "n_train = train_df.shape[0]\n",
        "\n",
        "y_train_pd = train_df[['Danceability']].copy()\n",
        "y_train    = y_train_pd.to_numpy()\n",
        "y_train    = np.reshape(y_train, n_train)\n",
        "\n",
        "x_train_pd = train_df.iloc[:, list(train_df.dtypes == float)].copy()\n",
        "x_train_pd = x_train_pd.drop(columns=['Danceability'])\n",
        "x_train    = x_train_pd.to_numpy()   \n",
        "x_train_std= KNN_Impute_iqrs(x_train_pd, 5) # change according to current agreement    \n",
        "#pd.set_option('display.max_columns', 500)                                      \n",
        "#train_df.head()"
      ],
      "metadata": {
        "id": "Rufi6RuECQHX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Func"
      ],
      "metadata": {
        "id": "vFoPts6b376S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CV Interpretation\n",
        "def CV_Average(score, msg):\n",
        "    fold = score.shape[0]\n",
        "    sum = 0\n",
        "    for f in range(fold):\n",
        "        sum += score[f]\n",
        "    print(msg)\n",
        "    print('average: ' + str(sum/fold))\n",
        "    print('indiv.: '+str(score))"
      ],
      "metadata": {
        "id": "T2oxVH5p3_vm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Output Manipulation\n",
        "def Reg_for_Cla(y):\n",
        "    y = y.round()\n",
        "    for i in range(y.shape[0]):\n",
        "        for j in range (y.shape[1]):\n",
        "            if   y[i][j] < 0:\n",
        "                y[i][j] = 0\n",
        "            elif y[i][j] > 9:\n",
        "                y[i][j] = 9\n",
        "    return y"
      ],
      "metadata": {
        "id": "zbx3wTqq4S2e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "_ABrxZ4dTUeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hist Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html#sklearn.ensemble.HistGradientBoostingClassifier)\n",
        "\n",
        "[Hist Gradient Boosting Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor)\n",
        "\n",
        "best 5f-cv avg: 1.687 (original input w/ NaN & rounded output)\n",
        "\n",
        "somehow regressor is better than classifier (maybe because considers ordered relation?)"
      ],
      "metadata": {
        "id": "0TxonjBbTYNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Gradient Boosting Decision Tree\n",
        "gbr = make_pipeline(HistGradientBoostingRegressor(loss='absolute_error'))\n",
        "gbr_round = TransformedTargetRegressor(regressor=HistGradientBoostingRegressor(loss='absolute_error'), inverse_func=np.round, check_inverse=False)"
      ],
      "metadata": {
        "id": "ndAJKh3PLd7z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Random Forest\n",
        "# can only used imputed data\n",
        "rf = make_pipeline(RandomForestRegressor(max_depth=2, max_samples=0.3, criterion='absolute_error'))\n",
        "rf.fit(x_train_std, y_train)"
      ],
      "metadata": {
        "id": "Ut3VvXBxaFnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cross Validation: change estimator name & x\n",
        "cv_score = cross_val_score(gbr, x_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
        "CV_Average(cv_score, \"original output\")\n",
        "cv_score = cross_val_score(gbr_round, x_train,     y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
        "CV_Average(cv_score, \"with rounding\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZYny5MYdRYG",
        "outputId": "a1d19015-cd7f-448d-ce2f-e8598eef56eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original output\n",
            "average: -1.6955145926034483\n",
            "indiv.: [-1.65224929 -1.69621278 -1.67112583 -1.70574927 -1.75223579]\n",
            "with rounding\n",
            "average: -1.6870704717530576\n",
            "indiv.: [-1.64676762 -1.68200349 -1.65492137 -1.6924869  -1.75917298]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Confusion Matrix on Classifier\n",
        "x_train3, x_eval, y_train3, y_eval = train_test_split(x_train, y_train, random_state=0)\n",
        "gbr_class = make_pipeline(HistGradientBoostingClassifier())\n",
        "gbr_model = gbr_class.fit(x_train3, y_train3)\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", \"true\"),]\n",
        "for title, normalize in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        gbr_model,\n",
        "        x_eval,\n",
        "        y_eval,\n",
        "        display_labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
        "        cmap=plt.cm.Blues,\n",
        "        normalize=normalize,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Zs1X4TPBCT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "5InxSfmxHWQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### load data\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\", delimiter=\",\", header=0)\n",
        "n_test = test_df.shape[0]\n",
        "\n",
        "id = test_df[['id']].copy()\n",
        "id = id.to_numpy()\n",
        "submit = np.zeros((n_test, 2))\n",
        "submit[:, 0] = id[:, 0]\n",
        "\n",
        "x_test_pd = test_df.iloc[:, list(test_df.dtypes == float)].copy()\n",
        "x_test    = x_test_pd.to_numpy()   \n",
        "x_test_std= KNN_Impute_iqrs(x_test_pd, 5) # change according to current agreement"
      ],
      "metadata": {
        "id": "dFuNgC7wHWAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### make prediction\n",
        "gbr_round.fit(x_train, y_train)\n",
        "submit[:, 1] = gbr.predict(x_test)\n",
        "\n",
        "df = pd.DataFrame(submit, columns = ['id','Danceability'])\n",
        "df = df.astype({\"id\": int})\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "C2FlqhzGLM8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}