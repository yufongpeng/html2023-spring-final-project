{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DqDuEVzvTDTu",
        "lqgWUGvTTOAV",
        "vFoPts6b376S"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Package Import"
      ],
      "metadata": {
        "id": "DqDuEVzvTDTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc7PKFk0zIna"
      },
      "outputs": [],
      "source": [
        "### import\n",
        "import random as rand\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy.stats import iqr\n",
        "\n",
        "!pip install -U liblinear-official\n",
        "from liblinear.liblinearutil import *\n",
        "from statsmodels.miscmodels.ordinal_model import OrderedModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data & Preprocess Func\n",
        "panda: y_train_pd, x_train_pd\n",
        "\n",
        "numpy: y_train, x_train (w/ missing value), x_train_std (imputed according to current method)"
      ],
      "metadata": {
        "id": "lqgWUGvTTOAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### missing value\n",
        "# x should be pandas dataframe\n",
        "def KNN_Impute(x, k):\n",
        "    knn_impute = KNNImputer(n_neighbors=k) # n_neighbors, weights\n",
        "    x = knn_impute.fit_transform(x)\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][1] = round(x[i][1])\n",
        "    return x\n",
        "\n",
        "def KNN_Impute_iqrs(x, k):\n",
        "    iqrs = x.apply(lambda x: np.nanquantile(x, 0.75) - np.nanquantile(x, 0.25))\n",
        "    x = x / iqrs\n",
        "    knn_impute = KNNImputer(n_neighbors=k) # n_neighbors, weights\n",
        "    x = knn_impute.fit_transform(x)\n",
        "    x = x * iqrs.to_numpy()\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][1] = round(x[i][1])\n",
        "    return x"
      ],
      "metadata": {
        "id": "lhgxBmg2_wLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### load training data with pandas\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\", delimiter=\",\", header=0)\n",
        "n_train = train_df.shape[0]\n",
        "\n",
        "y_train_pd = train_df[['Danceability']].copy()\n",
        "y_train    = y_train_pd.to_numpy()\n",
        "y_train    = np.reshape(y_train, n_train)\n",
        "\n",
        "x_train_pd = train_df.iloc[:, list(train_df.dtypes == float)].copy()\n",
        "x_train_pd = x_train_pd.drop(columns=['Danceability'])\n",
        "x_train    = x_train_pd.to_numpy()   \n",
        "x_train_std= KNN_Impute_iqrs(x_train_pd, 5) # change according to current agreement    \n",
        "#pd.set_option('display.max_columns', 500)                                      \n",
        "#train_df.head()"
      ],
      "metadata": {
        "id": "Rufi6RuECQHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Func"
      ],
      "metadata": {
        "id": "vFoPts6b376S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### CV Interpretation\n",
        "def CV_Average(score, msg):\n",
        "    fold = score.shape[0]\n",
        "    sum = 0\n",
        "    for f in range(fold):\n",
        "        sum += score[f]\n",
        "    print(msg)\n",
        "    print('average: ' + str(sum/fold))\n",
        "    print('indiv.: '+str(score))"
      ],
      "metadata": {
        "id": "T2oxVH5p3_vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Output Manipulation\n",
        "def Reg_for_Cla(y):\n",
        "    for i in range(y.shape[0]):\n",
        "        for j in range (y.shape[1]):\n",
        "            integer = math.floor(y[i][j])\n",
        "            trail = y[i][j] - integer\n",
        "            if trail < 0.1:\n",
        "                y[i][j] = integer\n",
        "            elif trail > 0.9:\n",
        "                y[i][j] = integer+1\n",
        "    return y"
      ],
      "metadata": {
        "id": "zbx3wTqq4S2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "_ABrxZ4dTUeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hist Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html#sklearn.ensemble.HistGradientBoostingClassifier)\n",
        "\n",
        "[Hist Gradient Boosting Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor)\n",
        "\n",
        "best 5f-cv avg: 1.697 (original input w/ NaN & original output)\n",
        "\n",
        "somehow regressor is better than classifier (maybe because considers ordered relation?)"
      ],
      "metadata": {
        "id": "0TxonjBbTYNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Gradient Boosting Decision Tree\n",
        "gbr = make_pipeline(HistGradientBoostingRegressor(loss='absolute_error'))\n",
        "gbr_trans = TransformedTargetRegressor(regressor=HistGradientBoostingRegressor(loss='absolute_error'), inverse_func=Reg_for_Cla, check_inverse=False)\n",
        "\n",
        "\n",
        "#   CV: change estimator name\n",
        "cv_score = cross_val_score(gbr_trans, x_train_std, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
        "CV_Average(cv_score, \"with iqrs impute\")\n",
        "cv_score = cross_val_score(gbr_trans, x_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
        "CV_Average(cv_score, \"with NaN\")"
      ],
      "metadata": {
        "id": "ndAJKh3PLd7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Ordered Model\n",
        "mod_prob = OrderedModel(y_train, x_train_std, distr='logit')\n",
        "res_prob = mod_prob.fit()\n",
        "#print(res_prob.summary())\n",
        "\n",
        "y_pred_class = res_prob.predict(x_train_std)\n",
        "y_pred= np.zeros((n_train))\n",
        "for i in range(n_train):\n",
        "    best_r = 0\n",
        "    for r in range(10):\n",
        "        if y_pred_class[i][r] > y_pred_class[i][best_r]:\n",
        "            best_r = r\n",
        "    y_pred[i] = best_r\n",
        "mean_absolute_error(y_train, y_pred)"
      ],
      "metadata": {
        "id": "VEDHHBrvA5JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "5InxSfmxHWQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### load data\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\", delimiter=\",\", header=0)\n",
        "n_test = test_df.shape[0]\n",
        "\n",
        "id = test_df[['id']].copy()\n",
        "id = id.to_numpy()\n",
        "submit = np.zeros((n_test, 2))\n",
        "submit[:, 0] = id[:, 0]\n",
        "\n",
        "x_test_pd = test_df.iloc[:, list(test_df.dtypes == float)].copy()\n",
        "x_test    = x_test_pd.to_numpy()   \n",
        "x_test_std= KNN_Impute_iqrs(x_test_pd, 5) # change according to current agreement    \n",
        "#pd.set_option('display.max_columns', 500)                                      \n",
        "#x_test_pd.head()"
      ],
      "metadata": {
        "id": "dFuNgC7wHWAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### make prediction\n",
        "gbr = make_pipeline(HistGradientBoostingRegressor(loss='absolute_error'))\n",
        "gbr.fit(x_train, y_train)\n",
        "submit[:, 1] = gbr.predict(x_test)\n",
        "\n",
        "df = pd.DataFrame(submit, columns = ['id','Danceability'])\n",
        "df = df.astype({\"id\": int})\n",
        "df.to_csv('submission.csv', index=False)\n",
        "#get rid of 0 column"
      ],
      "metadata": {
        "id": "C2FlqhzGLM8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}